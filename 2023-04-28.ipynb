{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb5a283-9029-4603-8ee7-62a081802737",
   "metadata": {},
   "source": [
    "#### 2023-04-28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f604e4-27ab-4754-9e9e-34c20904013a",
   "metadata": {},
   "source": [
    "##### 1교시 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34ceaa-239c-4fe9-808a-889bbe4d8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn LGBMClassifier에서 과적합을 방지하기 위해 높여야 하는 하이퍼파라미터는 다음 중 무엇인가?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f7d3519-8d41-4349-91e6-072deb0e6eb2",
   "metadata": {},
   "source": [
    "1. num_leaves\n",
    "2. min_child_samples\n",
    "3. max_depth\n",
    "4. learning_rate\n",
    "5. n_estimators\n",
    "\n",
    "답:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd6985-4697-4314-97b1-ab4929e3417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치 대신 hyperopt로 배이지안 최적화를 이용한 하이퍼파라미터 튜닝을 하는 이유를 서술하시오"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7228a6de-59a2-4d0b-a750-f45c5d9e6eed",
   "metadata": {},
   "source": [
    "수행시간을 줄이기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f09235-f70d-4379-9e32-62c5993679b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt에서 -1을 곱하는 이유는 무엇인가요?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbe70200-2469-4cbc-bf38-2b2b33b51f05",
   "metadata": {},
   "source": [
    "fmin() 함수는 아웃풋이 최소가 되는 x값을 찾아줌\n",
    "accuracy는 값이 큰 걸 찾는게 목표임\n",
    "근데 fmin()은 작은 게 나오기 때문에 accuracy 값이 큰 걸 찾아주려면 앞에 -1을 곱해서 \n",
    "가장 작은 값으로 만들어줘야 우리가 원하는 정확도를 구할 수 있음\n",
    "\n",
    "## HyperOpt는 최솟값을 최적으로 반환하기 때문에 높은 수치가 좋은 지표일 경우는 마이너스를 해서 반전을 시켜줘야한다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a071e124-0d79-4117-b552-e5a1a4efb9f1",
   "metadata": {},
   "source": [
    "precision =   TP   /  TP + FP\n",
    "(정밀도)\n",
    "TPR       =   TP   /  TP + FN\n",
    "FPR       =   FP   /  FP + TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8b266-de2f-4123-aefb-0b1762169db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음의 경우와 같은 실제 경우와 그에 대한 예측이 있을 때 정밀도와 재현율을 구하세요"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cab0890f-8beb-49b0-b57a-80abb92c696f",
   "metadata": {},
   "source": [
    "실제 : O O O X O X O O X X\n",
    "예측 : O O X X O O O O O X"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd9d428f-e2a1-4d7b-be98-62f47265d12a",
   "metadata": {},
   "source": [
    "정밀도 : 5/7\n",
    "재현율 : 5/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19323f6-7a87-42a2-a619-16a6da2a933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 중 앙상블 모델이 아닌 것은?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8160e0b5-822a-4211-8219-2e96537238cc",
   "metadata": {},
   "source": [
    "1. GBM\n",
    "2. 랜덤 포레스트\n",
    "3. XGBoost\n",
    "4. Decision Tree\n",
    "\n",
    "답: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921a902-d9a9-4719-9cfb-a66c117659a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수와 같은 의미의 용어를 쓰세요"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d45f9484-b0d3-4a18-981e-84cf831922b6",
   "metadata": {},
   "source": [
    "loss function : 손실함수\n",
    "error function : 오차함수\n",
    "cost function : 비용함수\n",
    "objective function : 목적함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23792dfc-a6c7-4598-9429-e9bf4a0b12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 방식의 차이점을 설명하시오"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b63f02ab-10e7-463a-b702-d56a871218db",
   "metadata": {},
   "source": [
    "bagging 방식 : 다른 데이터셋, 같은 알고리즘\n",
    "voting 방식 : 다른 알고리즘, 같은 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf18bb4-5418-4a9d-8971-c843ddde58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 기법의 조건"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2580eadc-bf6d-431d-bd3e-32d54ba57a99",
   "metadata": {},
   "source": [
    "- 각각의 분류기는 상호 _____ 이어야 한다.\n",
    "-> 독립\n",
    "\n",
    "- 각 분류기의 오분류율은 적어도 ____% 보다는 낮아야 한다.\n",
    "-> 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc36172-bb86-4522-ab1b-18a36b0acda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {       } 안을 채워넣으세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4e898bd-d8bf-411f-b89e-20743e7d3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10404d5f-7b92-4ce7-951d-edc33305e3b8",
   "metadata": {},
   "source": [
    "x : 0 ~ 20 까지 랜덤한 정수값\n",
    "y : -50 ~ 50 까지 간격이 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84c0d145-0159-455b-870e-e24e6092f1fa",
   "metadata": {},
   "source": [
    "'x' : hp.quniform('x',0,20)\n",
    "'y' : hp.quniform('y',-50,50,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "623e2794-af9d-49f6-afd9-d2d50dd66bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = { 'x' : hp.quniform('x',0,20,1),\n",
    "                 'y' : hp.quniform('y',-50,50,5)  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ec953cd-bb98-42a5-a14b-b2b3e6cfe44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <hyperopt.pyll.base.Apply at 0x1d66e0ba830>,\n",
       " 'y': <hyperopt.pyll.base.Apply at 0x1d66e0bbe50>}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bb51b-619c-4c0b-b4ed-608aa1ad5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective_func : x*y - x + y 함수를 만드세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10acdc00-028e-473c-84b0-f9c1ed9b2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "def objective_func(search_space): \n",
    "      x=search_space['x']\n",
    "      y=search_space['y']\n",
    "      retval= x*y -x+y\n",
    "      return retval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15401d00-7378-4037-ba72-f078b864df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmin() 함수 인자들을 채우세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6b09c4d1-c1e9-4956-9ca2-e5359088c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b3933b4-9f55-4ad1-8703-f5c05d4d392f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 1000.74trial/s, best loss: -459.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 9.0, 'y': -45.0}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_01 = fmin(fn= objective_func, \n",
    "            space= search_space, \n",
    "            algo= tpe.suggest,\n",
    "            max_evals=5, \n",
    "            trials= trials)\n",
    "best_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "314cebac-4da0-4ada-8bb4-a3d269298424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from pydataset import data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac9b5f-c880-45d4-b4da-75532662b7c8",
   "metadata": {},
   "source": [
    "##### 2교시 279p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83e98e80-b7b5-4bab-8167-376aa2f32b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45a8ebb8-fc65-437f-92ee-4c4dad267139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Time',axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0335821-1d56-44ca-9505-8066647c1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_features = df.iloc[:,:-1]\n",
    "y = y_labels = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1a71b60d-3c86-4b98-8993-15007bd22caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99.827251\n",
       "1     0.172749\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y.value_counts() / len(y)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "34cf434a-feed-4137-976c-8d25d24de0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9284e86e-7a8f-437d-a490-483a34ea289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8a335487-8182-4456-8a3b-221157256103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999204147794436"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "870293c2-bd9d-48cc-b6ca-5aefa0708959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d3c5f5a0-d1d5-4dea-95ad-057757699c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6edcdd0b-bcca-4ab0-9c53-ca84681aa9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85284    12]\n",
      " [   56    91]]\n",
      "정확도: 0.9992, 정밀도: 0.8835, 재현율: 0.6190,          F1: 0.7280, AUC:0.9688\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "290b02e0-ee6c-4663-b5cd-f3e4c4dd3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자로 사이킷런의 Estimator객체와, 학습/테스트 데이터 세트를 입력 받아서 학습/예측/평가 수행.\n",
    "def get_model_train_eval(model, X_train=None, X_test=None, y_train=None, y_test=None):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "87a0c01f-3549-49d3-a597-b7c1210a81e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85284    12]\n",
      " [   56    91]]\n",
      "정확도: 0.9992, 정밀도: 0.8835, 재현율: 0.6190,          F1: 0.7280, AUC:0.9688\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression 사용한 경우\n",
    "get_model_train_eval(lr_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "40988cb9-a711-411b-bee0-5b8c0c7b24c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85287     9]\n",
      " [   29   118]]\n",
      "정확도: 0.9996, 정밀도: 0.9291, 재현율: 0.8027,          F1: 0.8613, AUC:0.9800\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 사용한 경우\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000,\n",
    "                         num_leaves=64,\n",
    "                         n_jobs=-1,\n",
    "                         boost_from_average=False)\n",
    "\n",
    "\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "816f7569-f23c-4ea8-be9c-4228fed65820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 286p : 스케일링 StandardScaler 사용 -> 어느 한 칼럼의 데이터들이 마음에 들지 않아 바꿔주는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "07677584-efec-49fc-9c1e-ac8881146949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount 칼럼에 대하여 스케일링 StandardScaler 사용\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 방법 1. training으로 fit 한 후, transform()\n",
    "scaler = StandardScaler()\n",
    "df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "146153ad-e081-45b4-bdc0-0992c6d5a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2. 데이터 스케일링 후에, 분리\n",
    "X = X_features = df.iloc[:,:-1]\n",
    "y = y_labels = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f46c6a61-ce01-4ba8-ae93-174620431649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>-0.254117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.514355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244964   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342475   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.160686   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.140534   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073403   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.350151   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527 -0.254117   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561 -0.081839   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.313249   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  0.514355   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a58d5188-6ace-4188-aaf6-b33c8363b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85288     8]\n",
      " [   29   118]]\n",
      "정확도: 0.9996, 정밀도: 0.9365, 재현율: 0.8027,          F1: 0.8645, AUC:0.9829\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 사용한 경우\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000,\n",
    "                         num_leaves=64,\n",
    "                         n_jobs=-1,\n",
    "                         boost_from_average=False)\n",
    "\n",
    "\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5a0c9-3fff-494b-b1af-81e399c877b1",
   "metadata": {},
   "source": [
    "##### 3교시 287p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4eab449b-7f47-4642-9388-18daae0b2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount 칼럼에 대해 로그변환 사용\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.drop('Time',axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3dee6044-862c-4f18-9a99-651b6710cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = np.log1p(df['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e0cc4a7e-1cf8-4cef-b642-ae957a2387cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85288     8]\n",
      " [   29   118]]\n",
      "정확도: 0.9996, 정밀도: 0.9365, 재현율: 0.8027,          F1: 0.8645, AUC:0.9829\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 사용한 경우\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000,\n",
    "                         num_leaves=64,\n",
    "                         n_jobs=-1,\n",
    "                         boost_from_average=False)\n",
    "\n",
    "\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6739d916-7c0b-4389-b096-b5461649bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85284    12]\n",
      " [   56    91]]\n",
      "정확도: 0.9992, 정밀도: 0.8835, 재현율: 0.6190,          F1: 0.7280, AUC:0.9690\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegressions 사용한 경우\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "get_model_train_eval(lr_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "40adca95-5280-4e35-a799-b8888eedc69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(10)+np.log10(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1e36f071-a7a9-4e0a-bfbd-e52378c04e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.exp(1)) # np.log1p 랑 같은의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9ebfa868-8f97-42eb-905f-aca89938a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "41a4bc74-455a-4f81-baad-fd0978ce48fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3602684786.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[167], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    1/4 지점 : -1.5IQR\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# 288p ~ \n",
    "# IQR ( inter quantile range) \n",
    "1/4 지점 : -1.5IQR\n",
    "3/4 지점 : +1.5IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0c362952-3e10-40ea-b437-98828674b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e1440bdc-9cbd-48d9-b580-a8345a4b8f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.25"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(x,25)\n",
    "np.percentile(x,3/4*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872de65-bdc1-49d3-a9ca-139b53a3f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 연습\n",
    "1 ~ 200\n",
    "\n",
    "하위 이상치 x값\n",
    "상위 이상치 x값\n",
    "을 찾아주세요\n",
    "\n",
    "이상치 : 3/4 지점 - 1/4 지점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "66ae0a44-ee24-4c78-9a5a-506e18d4a7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하위 : -98.5\n",
      "상위 : 299.5\n"
     ]
    }
   ],
   "source": [
    "print('하위 :', np.percentile(x,25)-(1.5*(np.percentile(x,75)-(np.percentile(x,25)))))\n",
    "print('상위 :', np.percentile(x,75)+(1.5*(np.percentile(x,75)-(np.percentile(x,25)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "408a6a59-073a-4c9a-b320-e92466f0bd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25691.16"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.drop('Time',axis =1, inplace=True)\n",
    "df['Amount'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de6940-01eb-47e4-be63-7a4f11cb5eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Amount'] 의 하위 이상치, 상위 이상치의 갯수는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "799a3197-7d49-4fd6-bd67-fc5dbe598743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하위 :  -101.7475\n",
      "상위 :  184.5125\n"
     ]
    }
   ],
   "source": [
    "IQR = np.percentile(df['Amount'], 75) - np.percentile(df['Amount'], 25)\n",
    "print(\"하위 : \", np.percentile(df['Amount'],25) - 1.5*IQR) \n",
    "print(\"상위 : \", np.percentile(df['Amount'],75) + 1.5*IQR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f3f0801e-ff4b-4fcb-a21c-7eecfe05b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = np.percentile(df['Amount'],25) - 1.5*IQR\n",
    "high = np.percentile(df['Amount'],75) + 1.5*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c67db35d-0656-4ab3-9b3a-a11e28f9542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['Amount'] < low )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f38dc19b-70d2-40bb-8f51-71a733dc9206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31904"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['Amount'] > high )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06b89f-586c-4107-980b-c8af5a57ddcf",
   "metadata": {},
   "source": [
    "##### 5교시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e3f0e6b9-df45-434a-a146-4602d01eae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 아닌 관측치 관찰\n",
    "df_normal = df[df['Amount'] < np.percentile(x,75) + 1.5*IQR]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "112b61af-c400-4cea-a880-29591e45e27a",
   "metadata": {},
   "source": [
    "1. 로그 스케일링\n",
    "2. 데이터셋 분리\n",
    "3. LogisticRegression, LightGBM으로 각각 평가지표 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f16b297d-b7bf-49ff-8d32-b37f1f70529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14644\\3554993567.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal['Amount'] = np.log1p(df_normal['Amount'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[78697    15]\n",
      " [   50    94]]\n",
      "정확도: 0.9992, 정밀도: 0.8624, 재현율: 0.6528,          F1: 0.7431, AUC:0.9832\n",
      "========================================================\n",
      "오차 행렬\n",
      "[[78706     6]\n",
      " [   21   123]]\n",
      "정확도: 0.9997, 정밀도: 0.9535, 재현율: 0.8542,          F1: 0.9011, AUC:0.9870\n"
     ]
    }
   ],
   "source": [
    "df_normal['Amount'] = np.log1p(df_normal['Amount'])     # 1. 로그 스케일링\n",
    "\n",
    "y = df_normal.iloc[:, -1]\n",
    "X = df_normal.iloc[:, : -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)     # 2. 데이터셋 분리\n",
    "\n",
    "# 3. 평가지표 구하기\n",
    "# LogisticRegression    \n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "get_model_train_eval(lr_clf, X_train, X_test, y_train, y_test)\n",
    "print(\"========================================================\")\n",
    "# LightGBM\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 1000, num_leaves = 64, n_jobs = -1,\n",
    "                         boost_from_average = False)\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, y_train, y_test) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fcea8fc-4488-4deb-a72b-6fd332521f7f",
   "metadata": {},
   "source": [
    "X의 1% 만 뽑아서 X 라고 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b8ad08c1-7e20-4c34-85b4-78c1ac3dac5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127421</th>\n",
       "      <td>-0.358284</td>\n",
       "      <td>1.152559</td>\n",
       "      <td>1.294548</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.072125</td>\n",
       "      <td>-0.953804</td>\n",
       "      <td>0.785839</td>\n",
       "      <td>-0.114657</td>\n",
       "      <td>-0.502470</td>\n",
       "      <td>-0.539223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178713</td>\n",
       "      <td>-0.250572</td>\n",
       "      <td>-0.634429</td>\n",
       "      <td>-0.002175</td>\n",
       "      <td>0.346551</td>\n",
       "      <td>-0.132733</td>\n",
       "      <td>0.069603</td>\n",
       "      <td>0.246925</td>\n",
       "      <td>0.100464</td>\n",
       "      <td>1.270934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263881</th>\n",
       "      <td>-0.571229</td>\n",
       "      <td>1.325994</td>\n",
       "      <td>1.253170</td>\n",
       "      <td>4.037335</td>\n",
       "      <td>0.573932</td>\n",
       "      <td>3.267649</td>\n",
       "      <td>-0.911067</td>\n",
       "      <td>1.496866</td>\n",
       "      <td>-1.522247</td>\n",
       "      <td>1.415402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024638</td>\n",
       "      <td>0.348578</td>\n",
       "      <td>1.143326</td>\n",
       "      <td>-0.013162</td>\n",
       "      <td>-0.766468</td>\n",
       "      <td>-0.882032</td>\n",
       "      <td>0.533280</td>\n",
       "      <td>0.401678</td>\n",
       "      <td>0.178552</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103433</th>\n",
       "      <td>0.974613</td>\n",
       "      <td>-0.350143</td>\n",
       "      <td>0.360393</td>\n",
       "      <td>1.484236</td>\n",
       "      <td>-0.801989</td>\n",
       "      <td>-0.499769</td>\n",
       "      <td>-0.090965</td>\n",
       "      <td>0.172559</td>\n",
       "      <td>0.584740</td>\n",
       "      <td>0.157606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214332</td>\n",
       "      <td>-0.053625</td>\n",
       "      <td>-0.378858</td>\n",
       "      <td>-0.112321</td>\n",
       "      <td>0.457133</td>\n",
       "      <td>0.517524</td>\n",
       "      <td>-0.369436</td>\n",
       "      <td>-0.021903</td>\n",
       "      <td>0.018810</td>\n",
       "      <td>1.722075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177964</th>\n",
       "      <td>1.898070</td>\n",
       "      <td>0.508306</td>\n",
       "      <td>-0.699630</td>\n",
       "      <td>3.625149</td>\n",
       "      <td>0.492123</td>\n",
       "      <td>0.111834</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.049418</td>\n",
       "      <td>-1.084564</td>\n",
       "      <td>1.627896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329156</td>\n",
       "      <td>-0.251223</td>\n",
       "      <td>-0.799220</td>\n",
       "      <td>0.312881</td>\n",
       "      <td>-0.441921</td>\n",
       "      <td>-0.275426</td>\n",
       "      <td>-0.339787</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>-0.057665</td>\n",
       "      <td>1.171486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96701</th>\n",
       "      <td>-2.801212</td>\n",
       "      <td>-2.196221</td>\n",
       "      <td>0.602145</td>\n",
       "      <td>-1.046421</td>\n",
       "      <td>-0.948530</td>\n",
       "      <td>0.362579</td>\n",
       "      <td>-1.280901</td>\n",
       "      <td>1.205613</td>\n",
       "      <td>-0.357712</td>\n",
       "      <td>-0.621788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076624</td>\n",
       "      <td>0.371625</td>\n",
       "      <td>0.587742</td>\n",
       "      <td>-0.253313</td>\n",
       "      <td>-0.765052</td>\n",
       "      <td>0.551721</td>\n",
       "      <td>-0.111257</td>\n",
       "      <td>-0.156501</td>\n",
       "      <td>-0.598191</td>\n",
       "      <td>1.777095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83780</th>\n",
       "      <td>1.182574</td>\n",
       "      <td>-0.215672</td>\n",
       "      <td>1.229069</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>-1.162277</td>\n",
       "      <td>-0.322833</td>\n",
       "      <td>-0.680997</td>\n",
       "      <td>0.119513</td>\n",
       "      <td>1.053453</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154172</td>\n",
       "      <td>-0.101612</td>\n",
       "      <td>-0.136055</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>0.411874</td>\n",
       "      <td>0.227370</td>\n",
       "      <td>0.319185</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>0.025446</td>\n",
       "      <td>1.163669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>-5.519577</td>\n",
       "      <td>-6.991976</td>\n",
       "      <td>2.697300</td>\n",
       "      <td>-1.394760</td>\n",
       "      <td>5.913509</td>\n",
       "      <td>-4.919245</td>\n",
       "      <td>-4.284688</td>\n",
       "      <td>0.601913</td>\n",
       "      <td>2.312010</td>\n",
       "      <td>-1.480092</td>\n",
       "      <td>...</td>\n",
       "      <td>1.522020</td>\n",
       "      <td>0.677240</td>\n",
       "      <td>0.224681</td>\n",
       "      <td>0.840202</td>\n",
       "      <td>0.059830</td>\n",
       "      <td>0.808195</td>\n",
       "      <td>-0.221072</td>\n",
       "      <td>-0.356809</td>\n",
       "      <td>-0.037947</td>\n",
       "      <td>0.325890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204619</th>\n",
       "      <td>1.972728</td>\n",
       "      <td>-0.059865</td>\n",
       "      <td>-2.285701</td>\n",
       "      <td>0.387192</td>\n",
       "      <td>0.564709</td>\n",
       "      <td>-1.127841</td>\n",
       "      <td>0.540178</td>\n",
       "      <td>-0.403614</td>\n",
       "      <td>0.420034</td>\n",
       "      <td>-0.439407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004740</td>\n",
       "      <td>-0.206781</td>\n",
       "      <td>-0.607929</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>-0.779594</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>0.555388</td>\n",
       "      <td>-0.098759</td>\n",
       "      <td>-0.038074</td>\n",
       "      <td>1.696306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24425</th>\n",
       "      <td>1.153606</td>\n",
       "      <td>0.115139</td>\n",
       "      <td>0.578718</td>\n",
       "      <td>0.509888</td>\n",
       "      <td>-0.377366</td>\n",
       "      <td>-0.324067</td>\n",
       "      <td>-0.140144</td>\n",
       "      <td>0.091139</td>\n",
       "      <td>-0.166348</td>\n",
       "      <td>0.070173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142390</td>\n",
       "      <td>-0.167880</td>\n",
       "      <td>-0.517491</td>\n",
       "      <td>0.181334</td>\n",
       "      <td>0.207062</td>\n",
       "      <td>0.071329</td>\n",
       "      <td>0.095324</td>\n",
       "      <td>-0.019569</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>1.018179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76944</th>\n",
       "      <td>-1.397127</td>\n",
       "      <td>-0.625377</td>\n",
       "      <td>2.098903</td>\n",
       "      <td>-1.756019</td>\n",
       "      <td>-0.226544</td>\n",
       "      <td>-0.189529</td>\n",
       "      <td>-0.479799</td>\n",
       "      <td>0.269888</td>\n",
       "      <td>-1.124509</td>\n",
       "      <td>0.336249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>0.479940</td>\n",
       "      <td>1.529058</td>\n",
       "      <td>0.266917</td>\n",
       "      <td>0.069750</td>\n",
       "      <td>0.185127</td>\n",
       "      <td>-0.163086</td>\n",
       "      <td>0.301751</td>\n",
       "      <td>0.126075</td>\n",
       "      <td>1.481877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26285 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "127421 -0.358284  1.152559  1.294548  0.061350  0.072125 -0.953804  0.785839   \n",
       "263881 -0.571229  1.325994  1.253170  4.037335  0.573932  3.267649 -0.911067   \n",
       "103433  0.974613 -0.350143  0.360393  1.484236 -0.801989 -0.499769 -0.090965   \n",
       "177964  1.898070  0.508306 -0.699630  3.625149  0.492123  0.111834  0.154839   \n",
       "96701  -2.801212 -2.196221  0.602145 -1.046421 -0.948530  0.362579 -1.280901   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "83780   1.182574 -0.215672  1.229069  0.870968 -1.162277 -0.322833 -0.680997   \n",
       "28618  -5.519577 -6.991976  2.697300 -1.394760  5.913509 -4.919245 -4.284688   \n",
       "204619  1.972728 -0.059865 -2.285701  0.387192  0.564709 -1.127841  0.540178   \n",
       "24425   1.153606  0.115139  0.578718  0.509888 -0.377366 -0.324067 -0.140144   \n",
       "76944  -1.397127 -0.625377  2.098903 -1.756019 -0.226544 -0.189529 -0.479799   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "127421 -0.114657 -0.502470 -0.539223  ...  0.178713 -0.250572 -0.634429   \n",
       "263881  1.496866 -1.522247  1.415402  ...  0.024638  0.348578  1.143326   \n",
       "103433  0.172559  0.584740  0.157606  ... -0.214332 -0.053625 -0.378858   \n",
       "177964  0.049418 -1.084564  1.627896  ... -0.329156 -0.251223 -0.799220   \n",
       "96701   1.205613 -0.357712 -0.621788  ...  0.076624  0.371625  0.587742   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "83780   0.119513  1.053453 -0.215972  ... -0.154172 -0.101612 -0.136055   \n",
       "28618   0.601913  2.312010 -1.480092  ...  1.522020  0.677240  0.224681   \n",
       "204619 -0.403614  0.420034 -0.439407  ... -0.004740 -0.206781 -0.607929   \n",
       "24425   0.091139 -0.166348  0.070173  ... -0.142390 -0.167880 -0.517491   \n",
       "76944   0.269888 -1.124509  0.336249  ...  0.155274  0.479940  1.529058   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "127421 -0.002175  0.346551 -0.132733  0.069603  0.246925  0.100464  1.270934  \n",
       "263881 -0.013162 -0.766468 -0.882032  0.533280  0.401678  0.178552  0.009901  \n",
       "103433 -0.112321  0.457133  0.517524 -0.369436 -0.021903  0.018810  1.722075  \n",
       "177964  0.312881 -0.441921 -0.275426 -0.339787 -0.047181 -0.057665  1.171486  \n",
       "96701  -0.253313 -0.765052  0.551721 -0.111257 -0.156501 -0.598191  1.777095  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "83780   0.042174  0.411874  0.227370  0.319185  0.011759  0.025446  1.163669  \n",
       "28618   0.840202  0.059830  0.808195 -0.221072 -0.356809 -0.037947  0.325890  \n",
       "204619  0.012443 -0.779594  0.014809  0.555388 -0.098759 -0.038074  1.696306  \n",
       "24425   0.181334  0.207062  0.071329  0.095324 -0.019569  0.007092  1.018179  \n",
       "76944   0.266917  0.069750  0.185127 -0.163086  0.301751  0.126075  1.481877  \n",
       "\n",
       "[26285 rows x 29 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7ec7e753-b0e6-4261-8ee1-0aa80c5542fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([158717, 222039, 139029, 218192, 145746,  62593, 231415, 168532,\n",
       "             60871, 284082,\n",
       "            ...\n",
       "            119652, 166635, 221042, 127521, 181259,  49336, 161613, 273930,\n",
       "             96917, 247190],\n",
       "           dtype='int64', length=259807)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal[df_normal['Class'] == 0].sample(frac=0.99).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770465de-a7ec-43ae-9bb8-8db70618b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.drop(df_normal[df_normal['Class']== 0].sample(frac=0.99).index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d5c45b8c-e6b4-4458-82bd-e00a4e2feab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[784   2]\n",
      " [ 13 115]]\n",
      "정확도: 0.9836, 정밀도: 0.9829, 재현율: 0.8984,          F1: 0.9388, AUC:0.9817\n",
      "========================================================\n",
      "오차 행렬\n",
      "[[785   1]\n",
      " [ 13 115]]\n",
      "정확도: 0.9847, 정밀도: 0.9914, 재현율: 0.8984,          F1: 0.9426, AUC:0.9848\n"
     ]
    }
   ],
   "source": [
    "# X 의 1%만 뽑아서 X라고 합시다\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.drop('Time', axis =1, inplace = True)\n",
    "\n",
    "\n",
    "df_normal = df[df['Amount'] < np.percentile(x, 75 ) + 1.5*IQR]\n",
    "df_normal = df_normal.drop(df_normal[df_normal['Class']== 0].sample(frac=0.99).index)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "X = df_normal.iloc[:, : -1]\n",
    "y = df_normal.iloc[:, -1] \n",
    "\n",
    "\n",
    "# LogisticRegression\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "get_model_train_eval(lr_clf, X_train, X_test, y_train, y_test)\n",
    "print(\"========================================================\")\n",
    "# LightGBM\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 1000, num_leaves = 64, n_jobs = -1,\n",
    "                         boost_from_average = False)\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, y_train, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf77197-2ece-4f71-ae83-5431dbef6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 292p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dd72d6e6-2ebb-42d1-ba18-9e63ebf75add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9a3d8a92-3a02-4e6d-aad6-4436de7b0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1fe0bc63-0867-49db-a827-ca3692eda855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1838\n",
       "1     293\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "681a2228-7807-47ad-9ad4-cec27783ac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1838\n",
       "1    1838\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ebc6e5d9-39ee-4917-bcb5-c04910f70f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[771  15]\n",
      " [ 12 116]]\n",
      "정확도: 0.9705, 정밀도: 0.8855, 재현율: 0.9062,          F1: 0.8958, AUC:0.9828\n",
      "========================================================\n",
      "오차 행렬\n",
      "[[784   2]\n",
      " [ 13 115]]\n",
      "정확도: 0.9836, 정밀도: 0.9829, 재현율: 0.8984,          F1: 0.9388, AUC:0.9819\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "get_model_train_eval(lr_clf, X_train_over, X_test, y_train_over, y_test)\n",
    "print(\"========================================================\")\n",
    "# LightGBM\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 1000, num_leaves = 64, n_jobs = -1,\n",
    "                         boost_from_average = False)\n",
    "get_model_train_eval(lgbm_clf, X_train_over, X_test, y_train_over, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc1006-a80b-4216-bfdd-8467ba164f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 295p 스태킹 앙상블 (잘 쓰이진 않음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6791e9-8615-4af9-a54c-9f9894311fd0",
   "metadata": {},
   "source": [
    "##### 6교시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bc2ef97c-2d8b-4ac7-bd4e-c0ed7902ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ba1066d2-c773-4b4c-967f-ecba8cb8f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6eecfc43-0a69-413c-8314-689941e92303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6dad8122-7f7a-436a-9840-2417b7173b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "14dd5cf5-e46d-4f39-9c7f-a9877dde111b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e6662f16-749d-4099-8787-688c9514232c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 114)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "97797304-6582-4b33-a657-0d7764e67d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5e8ea2ad-f0f5-4ee6-ab55-9592671a380b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "204f4f4a-d108-46f6-9b87-61fd5bd3cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pred = pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b05ad777-dcee-4b5f-89b3-478d1e16830b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression(C=10)\n",
    "lr_final.fit(pred, y_test)\n",
    "final_pred = lr_final.predict(pred)\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c1cc831e-83a5-4b81-a57e-a39a1543c535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3843820d-bc73-4a9b-b248-418e30e74745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cb185-780e-4030-8bdf-b36958b04904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300p   CV 세트 기반의 스태킹 -> 잘 안쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e5b7e270-2cba-4e8b-af6f-3731f59b73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "169b064d-6155-44ca-8e1c-564cd923baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "RandomForestClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "DecisionTreeClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "AdaBoostClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "720a8d79-99dd-4732-a141-8f5f8f072a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 Shape: (455, 30) 원본 테스트 피처 Shape: (114, 30)\n",
      "스태킹 학습 피처 데이터 Shape: (455, 4) 스태킹 테스트 피처 데이터 Shape: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
    "      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "fd30d26b-1f8b-4f7f-9314-ad4790533039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80537c44-511d-461e-8faf-03a0abe9b0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
